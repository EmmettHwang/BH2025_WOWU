"""
ë¬¸ì„œ ë¡œë” ëª¨ë“ˆ
PDF, DOCX, TXT íŒŒì¼ì„ ë¡œë“œí•˜ê³  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
"""

import os
from typing import List, Dict
from pathlib import Path
import PyPDF2
import docx

# LangChain imports - ë²„ì „ í˜¸í™˜ì„± ì²˜ë¦¬
try:
    from langchain_text_splitters import RecursiveCharacterTextSplitter
except ImportError:
    from langchain.text_splitter import RecursiveCharacterTextSplitter

try:
    from langchain_core.documents import Document
except ImportError:
    from langchain.schema import Document


class DocumentLoader:
    """ë¬¸ì„œ ë¡œë“œ ë° ì²­í‚¹ í´ë˜ìŠ¤"""
    
    def __init__(self, chunk_size: int = 1000, chunk_overlap: int = 200):
        """
        Args:
            chunk_size: ì²­í¬ í¬ê¸° (í† í° ìˆ˜)
            chunk_overlap: ì²­í¬ ê°„ ê²¹ì¹¨ (í† í° ìˆ˜)
        """
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            length_function=len,
            separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""]
        )
    
    def load_pdf(self, file_path: str) -> str:
        """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                text = ""
                for page in pdf_reader.pages:
                    text += page.extract_text() + "\n"
                return text.strip()
        except Exception as e:
            print(f"âŒ PDF ë¡œë“œ ì‹¤íŒ¨: {file_path}, ì˜¤ë¥˜: {e}")
            return ""
    
    def load_docx(self, file_path: str) -> str:
        """DOCX íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            doc = docx.Document(file_path)
            text = "\n".join([paragraph.text for paragraph in doc.paragraphs])
            return text.strip()
        except Exception as e:
            print(f"âŒ DOCX ë¡œë“œ ì‹¤íŒ¨: {file_path}, ì˜¤ë¥˜: {e}")
            return ""
    
    def load_txt(self, file_path: str) -> str:
        """TXT íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                return file.read().strip()
        except Exception as e:
            print(f"âŒ TXT ë¡œë“œ ì‹¤íŒ¨: {file_path}, ì˜¤ë¥˜: {e}")
            return ""
    
    def load_document(self, file_path: str, metadata: Dict = None) -> List[Document]:
        """
        íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ì ì ˆí•œ ë¡œë”ë¡œ ë¬¸ì„œ ë¡œë“œ í›„ ì²­í‚¹
        
        Args:
            file_path: íŒŒì¼ ê²½ë¡œ
            metadata: ë©”íƒ€ë°ì´í„° (ì˜ˆ: {"source": "ê°•ì˜ë¡", "date": "2024-01-01"})
            
        Returns:
            ì²­í¬ë¡œ ë‚˜ë‰œ Document ë¦¬ìŠ¤íŠ¸
        """
        file_ext = Path(file_path).suffix.lower()
        
        # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        if file_ext == '.pdf':
            text = self.load_pdf(file_path)
        elif file_ext in ['.docx', '.doc']:
            text = self.load_docx(file_path)
        elif file_ext == '.txt':
            text = self.load_txt(file_path)
        else:
            print(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}")
            return []
        
        if not text:
            print(f"âš ï¸ ë¹ˆ ë¬¸ì„œ: {file_path}")
            return []
        
        # ë©”íƒ€ë°ì´í„° ì„¤ì •
        if metadata is None:
            metadata = {}
        
        metadata.update({
            'source': os.path.basename(file_path),
            'file_path': file_path,
            'file_type': file_ext
        })
        
        # í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
        chunks = self.text_splitter.split_text(text)
        
        # Document ê°ì²´ë¡œ ë³€í™˜
        documents = []
        for i, chunk in enumerate(chunks):
            chunk_metadata = metadata.copy()
            chunk_metadata['chunk_id'] = i
            chunk_metadata['total_chunks'] = len(chunks)
            
            doc = Document(
                page_content=chunk,
                metadata=chunk_metadata
            )
            documents.append(doc)
        
        print(f"âœ… ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ: {os.path.basename(file_path)} ({len(documents)}ê°œ ì²­í¬)")
        return documents
    
    def load_directory(self, directory_path: str, metadata: Dict = None) -> List[Document]:
        """
        ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  ë¬¸ì„œ ë¡œë“œ
        
        Args:
            directory_path: ë””ë ‰í† ë¦¬ ê²½ë¡œ
            metadata: ê³µí†µ ë©”íƒ€ë°ì´í„°
            
        Returns:
            ëª¨ë“  ë¬¸ì„œì˜ ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        all_documents = []
        
        for filename in os.listdir(directory_path):
            file_path = os.path.join(directory_path, filename)
            
            if os.path.isfile(file_path):
                file_ext = Path(file_path).suffix.lower()
                if file_ext in ['.pdf', '.docx', '.doc', '.txt']:
                    docs = self.load_document(file_path, metadata)
                    all_documents.extend(docs)
        
        print(f"ğŸ“š ë””ë ‰í† ë¦¬ ë¡œë“œ ì™„ë£Œ: {len(all_documents)}ê°œ ì²­í¬")
        return all_documents


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    loader = DocumentLoader(chunk_size=500, chunk_overlap=50)
    
    # ìƒ˜í”Œ í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
    sample_text = """
    ë°”ì´ì˜¤í—¬ìŠ¤ ì‚°ì—… ê°œìš”
    
    ë°”ì´ì˜¤í—¬ìŠ¤ ì‚°ì—…ì€ ìƒëª…ê³µí•™ ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ì¸ê°„ì˜ ê±´ê°•ê³¼ ì‚¶ì˜ ì§ˆì„ í–¥ìƒì‹œí‚¤ëŠ” ì‚°ì—…ì…ë‹ˆë‹¤.
    ì£¼ìš” ë¶„ì•¼ë¡œëŠ” ì‹ ì•½ ê°œë°œ, ì˜ë£Œê¸°ê¸°, ë””ì§€í„¸ í—¬ìŠ¤ì¼€ì–´ ë“±ì´ ìˆìŠµë‹ˆë‹¤.
    
    mRNA ë°±ì‹  ê¸°ìˆ 
    
    mRNA ë°±ì‹ ì€ ë©”ì‹ ì € RNAë¥¼ ì´ìš©í•˜ì—¬ ìš°ë¦¬ ëª¸ì˜ ì„¸í¬ê°€ íŠ¹ì • ë‹¨ë°±ì§ˆì„ ìƒì„±í•˜ë„ë¡ ì§€ì‹œí•©ë‹ˆë‹¤.
    ì´ ê¸°ìˆ ì€ COVID-19 íŒ¬ë°ë¯¹ ë™ì•ˆ ë¹ ë¥´ê²Œ ë°œì „í•˜ì˜€ìœ¼ë©°, í–¥í›„ ì•” ì¹˜ë£Œ ë“±ì—ë„ í™œìš©ë  ì „ë§ì…ë‹ˆë‹¤.
    """
    
    os.makedirs("./test_docs", exist_ok=True)
    with open("./test_docs/sample.txt", "w", encoding="utf-8") as f:
        f.write(sample_text)
    
    docs = loader.load_document("./test_docs/sample.txt", {"subject": "ë°”ì´ì˜¤í—¬ìŠ¤ ê¸°ì´ˆ"})
    
    print("\n=== ë¡œë“œëœ ë¬¸ì„œ ===")
    for i, doc in enumerate(docs):
        print(f"\nğŸ“„ ì²­í¬ {i+1}:")
        print(f"ë‚´ìš©: {doc.page_content[:100]}...")
        print(f"ë©”íƒ€ë°ì´í„°: {doc.metadata}")
